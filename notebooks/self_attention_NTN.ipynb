{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "o1 = torch.Tensor([[1,2,3], [1,2,3]]) # batch_size * embed_dim\n",
    "o2 = torch.Tensor([[4,5,6], [4,5,6]]) # batch_size * embed_dim\n",
    "o2 = torch.Tensor([[4,5,6], [4,5,6]]) # batch_size * embed_dim\n",
    "tensor_layer = torch.Tensor([[[1,2,3], \n",
    "                              [4,5,6],\n",
    "                             [7,8,9]], \n",
    "                             \n",
    "                             [[1,2,3], \n",
    "                              [4,5,6],\n",
    "                             [7,8,9]],\n",
    "                             \n",
    "                             [[1,2,3], \n",
    "                              [4,5,6],\n",
    "                             [7,8,9]]])\n",
    "\n",
    "# we flatten each matrix\n",
    "tensor_product = o1.mm(tensor_layer.view(3, -1)) # view changes shape, mm is matmul\n",
    "# # |tensor_product| = (batch_size, unknown_dim * tensor_dim)\n",
    "# tensor_product = tensor_product.view(batch_size, -1, unknown_dim).bmm(o2.unsqueeze(1).permute(0,2,1).contiguous()).squeeze()\n",
    "# tensor_product = tensor_product.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "v = np.array([0.1,0.2,0.3])\n",
    "w = np.array([0.4,0.5,0.6])\n",
    "e = np.matmul(np.transpose(v), w) # this gives a scalar !\n",
    "sigmoid(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = torch.einsum('ijk,ck,cj->ci', tensor_layer, o1, o2)\n",
    "\n",
    "# svo = torch.concat([vs,vo], 1) \n",
    "# final = torch.matmul(svo, W, name='final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_layer.view(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2])\n",
    "y = np.array([5, 6])\n",
    "\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "Y = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "Z = np.matmul(X, np.transpose(Y)) # because we want rows with rows, columns with columns \n",
    "\n",
    "a = np.matmul(x, X)\n",
    "b = np.matmul(y, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention = np.dot(a, np.transpose(b)) # both row vectors\n",
    "self_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[17, 23],\n",
       "        [39, 53]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_tensor = np.array([Z])\n",
    "Z_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear_prod1 = np.einsum('ijk,j, k', Z_tensor, x, y) # we get a scalar for each slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear_prod2 = np.einsum('jk,j, k', Z, x, y) # we get just one scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1249])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilinear_prod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilinear_prod2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
